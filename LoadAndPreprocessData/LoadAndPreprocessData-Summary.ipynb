{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LoadAndPreprocessData-Summary.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMEW3RxYmTXnWF9CldsT8jV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"k-Sx7RbMDPxs","colab_type":"text"},"source":["#Here i will do a preproccessing compilation with steps"]},{"cell_type":"markdown","metadata":{"id":"kXXaiMfCDd_L","colab_type":"text"},"source":["#Basic methods for training\n","\n","To train a model with this dataset you will want the data:\n","\n","    To be well shuffled.\n","    To be batched.\n","    Batches to be available as soon as possible.\n","\n","These features can be easily added using the tf.data api."]},{"cell_type":"markdown","metadata":{"id":"8x_zGWLsGnBR","colab_type":"text"},"source":["#Cache\n","If you use cache memory, the preprocessing will be faster, but it will consume memory, check last part of https://www.tensorflow.org/tutorials/load_data/images\n"]},{"cell_type":"markdown","metadata":{"id":"NyGQ_FHPkPOg","colab_type":"text"},"source":["#Types of data (tensorflow)\n"," <ul> \n","  <li>MapDataset</li>\n","  <li>PaddedBatchDataset: i think this one is just a BatchDataset but we used the padded function</li>\n","  <li>SparseTensor: parece que es para textos/Characters</li>\n","  <li>RaggedTensor: parece que es para textos/Characters: Ragged tensors are the TensorFlow equivalent of nested variable-length lists. They make it easy to store and process data with non-uniform shapes.. https://www.tensorflow.org/guide/ragged_tensor</li>\n","  <li>TensorSliceDataset </li>\n","  <li>TFRecordDatasetV2</li>\n"," </ul>"]},{"cell_type":"code","metadata":{"id":"_j-nvUu8DczV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rCm8UyflAiL","colab_type":"text"},"source":["#Useful functions:\n","```\n","tf.data.Dataset.padded_batch\n","```\n","Example: Before being passed into the model, the datasets need to be batched. Typically, the examples inside of a batch need to be the same size and shape. But, the examples in these datasets are not all the same size â€” each line of text had a different number of words. So use tf.data.Dataset.padded_batch (instead of batch) to pad the examples to the same size."]},{"cell_type":"markdown","metadata":{"id":"HTmHH38pntJC","colab_type":"text"},"source":["#Some other notes:\n","remember to do a summary of the basics.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8wzC-jZSZqyA","colab_type":"text"},"source":["#To save and load data:\n","Basically you have to do a process of preprocessing the data, saving it, then decoding it when you have to use it"]},{"cell_type":"markdown","metadata":{"id":"dBzwHsZMolMg","colab_type":"text"},"source":["#Optimizators and loss functions to use with each model:\n","<ul>\n","  <li>For a `softmax` categorization model, use sparse_categorical_crossentropy as the loss function. You can try other optimizers, but adam is very common.</li>\n","</ul>"]},{"cell_type":"code","metadata":{"id":"eVy8B6j4lIl8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}