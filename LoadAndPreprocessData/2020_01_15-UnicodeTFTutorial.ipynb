{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2020_01_15-UnicodeTFTutorial.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNCcXygYbzstrZ7Uyz3pUB+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ophVmDxupL2-","colab_type":"code","colab":{}},"source":["#https://www.tensorflow.org/tutorials/load_data/unicode"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxSYc6y2E-uC","colab_type":"text"},"source":["Models that process natural language often handle different languages with different character sets. Unicode is a standard encoding system that is used to represent character from almost all languages. Each character is encoded using a unique integer code point between 0 and `0x10FFFF.` A Unicode string is a sequence of zero or more code points.\n","\n","This tutorial shows how to represent Unicode strings in TensorFlow and manipulate them using Unicode equivalents of standard string ops. It separates Unicode strings into tokens based on script detection."]},{"cell_type":"code","metadata":{"id":"8dNrkfdMErMV","colab_type":"code","outputId":"7231a6f5-4dae-487a-b2fb-5e06b3fea3bf","executionInfo":{"status":"ok","timestamp":1579205771538,"user_tz":360,"elapsed":9432,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","# TensorFlow and tf.keras\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Rm7_RmkFFKp","colab_type":"text"},"source":["#The `tf.string` data type\n","The basic TensorFlow tf.string dtype allows you to build tensors of byte strings. Unicode strings are utf-8 encoded by default."]},{"cell_type":"code","metadata":{"id":"AJOiW0xgErdd","colab_type":"code","outputId":"ea12c447-ad1d-40f2-8784-79a0e57b53ab","executionInfo":{"status":"ok","timestamp":1579205771849,"user_tz":360,"elapsed":9734,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.constant(u\"Thanks üòä\")\n"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"TjP5xDS2FKno","colab_type":"code","outputId":"42489586-efc8-4c35-f8db-c0f71ae585fe","executionInfo":{"status":"ok","timestamp":1579205771852,"user_tz":360,"elapsed":9727,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#A tf.string tensor can hold byte strings of varying lengths because the byte strings are treated as atomic units. \n","#The string length is not included in the tensor dimensions.\n","tf.constant([u\"You're\", u\"welcome!\"]).shape\n"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([2])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"vkOxQjZ3FU77","colab_type":"text"},"source":["#Representing Unicode\n","\n","There are two standard ways to represent a Unicode string in TensorFlow:\n","\n","    string scalar ‚Äî where the sequence of code points is encoded using a known character encoding.\n","    int32 vector ‚Äî where each position contains a single code point.\n","\n","For example, the following three values all represent the Unicode string \"ËØ≠Ë®ÄÂ§ÑÁêÜ\" (which means \"language processing\" in Chinese):"]},{"cell_type":"code","metadata":{"id":"zcXeXLbEFQh-","colab_type":"code","outputId":"9cba43ad-160f-4939-8c49-c94c1f68fcbc","executionInfo":{"status":"ok","timestamp":1579205771857,"user_tz":360,"elapsed":9725,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Unicode string, represented as a UTF-8 encoded string scalar.\n","text_utf8 = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n","text_utf8"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"421NpDyuFb7j","colab_type":"code","outputId":"f4b3f52b-2a2e-4480-99de-88df85cf658a","executionInfo":{"status":"ok","timestamp":1579205771860,"user_tz":360,"elapsed":9720,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Unicode string, represented as a UTF-16-BE encoded string scalar.\n","text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16-BE\")) #This time we used another encoding type\n","text_utf16be"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"jKCbjd1yFg5P","colab_type":"code","outputId":"813e4398-b0e1-4906-de04-305eafb8076d","executionInfo":{"status":"ok","timestamp":1579205771861,"user_tz":360,"elapsed":9713,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Unicode string, represented as a vector of Unicode code points.\n","text_chars = tf.constant([ord(char) for char in u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"]) \n","text_chars #Each integer is a character, a 'code point'"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"4yv85Up3FyVU","colab_type":"text"},"source":["#Converting between representations\n","\n","TensorFlow provides operations to convert between these different representations:\n","\n","    tf.strings.unicode_decode: Converts an encoded string scalar to a vector of code points.\n","    tf.strings.unicode_encode: Converts a vector of code points to an encoded string scalar.\n","    tf.strings.unicode_transcode: Converts an encoded string scalar to a different encoding.\n"]},{"cell_type":"code","metadata":{"id":"k2P66N-tFqwp","colab_type":"code","outputId":"372eee48-cd92-419b-ff3d-a6f8f7ec12d5","executionInfo":{"status":"ok","timestamp":1579205771862,"user_tz":360,"elapsed":9706,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.strings.unicode_decode(text_utf8,input_encoding='UTF-8') #Pasa de utf-8 a int\n","\n"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"feB-cRG3GCPv","colab_type":"code","outputId":"7ae84900-4798-4034-ae38-e0a3180b827a","executionInfo":{"status":"ok","timestamp":1579205772009,"user_tz":360,"elapsed":9845,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.strings.unicode_encode(text_chars,output_encoding='UTF-8') #pasa de int a utf-8\n"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"TIlfyLEKGLLK","colab_type":"code","outputId":"0e2c050a-8347-487f-a5a2-86ec72b416d4","executionInfo":{"status":"ok","timestamp":1579205772011,"user_tz":360,"elapsed":9839,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.strings.unicode_transcode(text_utf8,input_encoding='UTF8',output_encoding='UTF-16-BE') #cambia de utf-8 a utf-16-be\n","#Nota, recuerda que todos estos fueron obtenidos a partir de la string de characters chinos\n"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"HsnGod1qGa14","colab_type":"text"},"source":["#Batch dimensions\n","\n","When decoding multiple strings, the number of characters in each string may not be equal. The return result is a `tf.RaggedTensor`, where the length of the innermost dimension varies depending on the number of characters in each string:"]},{"cell_type":"code","metadata":{"id":"26uFZnBbGVgb","colab_type":"code","outputId":"9c2462d9-e71f-4462-bbf7-d7febac6f3e5","executionInfo":{"status":"ok","timestamp":1579205772011,"user_tz":360,"elapsed":9831,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["# A batch of Unicode strings, each represented as a UTF8-encoded string.\n","batch_utf8 = [s.encode('UTF-8') for s in [u'h√Éllo',  u'What is the weather tomorrow',  u'G√∂√∂dnight', u'üòä']] #get the string in UTF-8\n","batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,input_encoding='UTF-8') #pass the utf-8 to string, because each sentence has different length, the arrays have different length\n","for sentence_chars in batch_chars_ragged.to_list():\n","  print(sentence_chars)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[104, 195, 108, 108, 111]\n","[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n","[71, 246, 246, 100, 110, 105, 103, 104, 116]\n","[128522]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2NpoEo1wG2ao","colab_type":"text"},"source":["You can use this `tf.RaggedTensor` directly (when strings are of different length), or convert it to a dense tf.Tensor with padding or a `tf.SparseTensor` using the methods `tf.RaggedTensor.to_tensor` (when strings are the same length) and `tf.RaggedTensor.to_sparse`."]},{"cell_type":"code","metadata":{"id":"JIQVLmZKGmUu","colab_type":"code","outputId":"b7bae473-be08-46d8-8339-41d6b7d0b28d","executionInfo":{"status":"ok","timestamp":1579205772013,"user_tz":360,"elapsed":9825,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"source":["#basically, like the text tutorial, we are padding the data so its input shape is the consistent.\n","batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n","print(batch_chars_padded.numpy())\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[[   104    195    108    108    111     -1     -1     -1     -1     -1\n","      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n","      -1     -1     -1     -1     -1     -1     -1     -1]\n"," [    87    104     97    116     32    105    115     32    116    104\n","     101     32    119    101     97    116    104    101    114     32\n","     116    111    109    111    114    114    111    119]\n"," [    71    246    246    100    110    105    103    104    116     -1\n","      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n","      -1     -1     -1     -1     -1     -1     -1     -1]\n"," [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n","      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n","      -1     -1     -1     -1     -1     -1     -1     -1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c4iQHHwhHC0f","colab_type":"code","outputId":"43aca144-cd31-4a7a-89a2-a1927f41cf15","executionInfo":{"status":"ok","timestamp":1579205772015,"user_tz":360,"elapsed":9821,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":940}},"source":["batch_chars_sparse = batch_chars_ragged.to_sparse()\n","print(batch_chars_sparse) #No estoy seguro espec√≠ficamente para que es esto\n","batch_chars_sparse #es un SparseTensor"],"execution_count":14,"outputs":[{"output_type":"stream","text":["SparseTensor(indices=tf.Tensor(\n","[[ 0  0]\n"," [ 0  1]\n"," [ 0  2]\n"," [ 0  3]\n"," [ 0  4]\n"," [ 1  0]\n"," [ 1  1]\n"," [ 1  2]\n"," [ 1  3]\n"," [ 1  4]\n"," [ 1  5]\n"," [ 1  6]\n"," [ 1  7]\n"," [ 1  8]\n"," [ 1  9]\n"," [ 1 10]\n"," [ 1 11]\n"," [ 1 12]\n"," [ 1 13]\n"," [ 1 14]\n"," [ 1 15]\n"," [ 1 16]\n"," [ 1 17]\n"," [ 1 18]\n"," [ 1 19]\n"," [ 1 20]\n"," [ 1 21]\n"," [ 1 22]\n"," [ 1 23]\n"," [ 1 24]\n"," [ 1 25]\n"," [ 1 26]\n"," [ 1 27]\n"," [ 2  0]\n"," [ 2  1]\n"," [ 2  2]\n"," [ 2  3]\n"," [ 2  4]\n"," [ 2  5]\n"," [ 2  6]\n"," [ 2  7]\n"," [ 2  8]\n"," [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n","[   104    195    108    108    111     87    104     97    116     32\n","    105    115     32    116    104    101     32    119    101     97\n","    116    104    101    114     32    116    111    109    111    114\n","    114    111    119     71    246    246    100    110    105    103\n","    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fe97ed41320>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"wvr72umMHQHb","colab_type":"code","outputId":"3c5d9fc0-3231-461d-e5df-252eb58cee60","executionInfo":{"status":"ok","timestamp":1579205778787,"user_tz":360,"elapsed":16585,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#When encoding multiple strings with the same lengths, a tf.Tensor may be used as input:\n","tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],output_encoding='UTF-8')\n"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"W_JO7SVIHzQd","colab_type":"code","outputId":"ba1753f6-3e1b-4e7c-a558-3fef82a1280b","executionInfo":{"status":"ok","timestamp":1579205778790,"user_tz":360,"elapsed":16581,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["#When encoding multiple strings with varyling length, a tf.RaggedTensor should be used as input:\n","tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8') #batch_chars_ragged is a collection of integers of different lengths\n"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=string, numpy=\n","array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n","       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"GLrhh1iYIEf-","colab_type":"code","outputId":"cd9d2459-1dfa-401a-bf88-cbf568eceb5b","executionInfo":{"status":"ok","timestamp":1579205778945,"user_tz":360,"elapsed":16729,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["#If you have a tensor with multiple strings in padded or sparse format, then convert it to a tf.RaggedTensor before calling unicode_encode:\n","tf.strings.unicode_encode(tf.RaggedTensor.from_sparse(batch_chars_sparse),output_encoding='UTF-8') #encode era para de code points a encoded string\n"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=string, numpy=\n","array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n","       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"uqyOLjEnIfbQ","colab_type":"code","outputId":"7877d948-b7e3-4e57-b6e6-cb192ce71ac4","executionInfo":{"status":"ok","timestamp":1579205778947,"user_tz":360,"elapsed":16724,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["#Como que hemos hecho la misma operaci√≥n pero por pasos con diferentes par√°metros para que funcione...\n","tf.strings.unicode_encode(tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),output_encoding='UTF-8')\n"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=string, numpy=\n","array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n","       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"QMBeRRiGIv1i","colab_type":"text"},"source":["#Unicode operations\n","Character length\n","\n","The `tf.strings.length` operation has a parameter unit, which indicates how lengths should be computed. unit defaults to \"BYTE\", but it can be set to other values, such as \"UTF8_CHAR\" or \"UTF16_CHAR\", to determine the number of Unicode codepoints in each encoded string."]},{"cell_type":"code","metadata":{"id":"qIQbtxF4IjNZ","colab_type":"code","outputId":"09e14211-8315-4569-e810-312af8814bd3","executionInfo":{"status":"ok","timestamp":1579205778948,"user_tz":360,"elapsed":16719,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Note that the final character takes up 4 bytes in UTF8.\n","thanks = u'Thanks üòä'.encode('UTF-8') #6 bytes of thanks, 1 of space, 4 of emoji\n","num_bytes = tf.strings.length(thanks).numpy()\n","num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n","print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["11 bytes; 8 UTF-8 characters\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VW70vZfYJjuC","colab_type":"text"},"source":["#Character substrings\n","\n","Similarly, the `tf.strings.substr` operation accepts the \"unit\" parameter, and uses it to determine what kind of offsets the \"pos\" and \"len\" paremeters contain."]},{"cell_type":"code","metadata":{"id":"RtTBkNnJJYFz","colab_type":"code","outputId":"8f9bea05-4fa5-4a2a-a259-482bdcefecd4","executionInfo":{"status":"ok","timestamp":1579205778949,"user_tz":360,"elapsed":16712,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# default: unit='BYTE'. With len=1, we return a single byte.\n","tf.strings.substr(thanks, pos=7, len=1).numpy() #Basically take a byte from the encoding\n"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'\\xf0'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"KMiZHZmLJplU","colab_type":"code","outputId":"ba715c8d-8b73-4d7a-9f2d-8757919a1f8e","executionInfo":{"status":"ok","timestamp":1579205778950,"user_tz":360,"elapsed":16705,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Specifying unit='UTF8_CHAR', we return a single character, which in this case\n","# is 4 bytes. (The emoji)\n","print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy()) "],"execution_count":21,"outputs":[{"output_type":"stream","text":["b'\\xf0\\x9f\\x98\\x8a'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AYf3PMbMJ7Lf","colab_type":"text"},"source":["#Split Unicode strings\n","\n","The `tf.strings.unicode_split` operation splits unicode strings into substrings of individual characters:"]},{"cell_type":"code","metadata":{"id":"Kb0u6unRJ2iS","colab_type":"code","outputId":"4f328e47-7321-4cb2-f0ab-cb621fdbefe3","executionInfo":{"status":"ok","timestamp":1579205779090,"user_tz":360,"elapsed":16838,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["tf.strings.unicode_split(thanks, 'UTF-8').numpy() #every letter, space, emoji\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"gPY1vgwFKFGR","colab_type":"text"},"source":["#Byte offsets for characters\n","\n","To align the character tensor generated by `tf.strings.unicode_decode` with the original string, it's useful to know the offset for where each character begins. The method `tf.strings.unicode_decode_with_offsets` is similar to unicode_decode, except that it returns a second tensor containing the start offset of each character."]},{"cell_type":"code","metadata":{"id":"__qsY02rKAmj","colab_type":"code","outputId":"0b11713f-83b1-45d4-ff15-68d66dbf4b53","executionInfo":{"status":"ok","timestamp":1579205779091,"user_tz":360,"elapsed":16831,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["#the offset is where each character starts\n","codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"üéàüéâüéä\", 'UTF-8')\n","\n","for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n","  print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["At byte offset 0: codepoint 127880\n","At byte offset 4: codepoint 127881\n","At byte offset 8: codepoint 127882\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-_w7QPSOKaEQ","colab_type":"text"},"source":["#Unicode scripts\n","\n","Each Unicode code point belongs to a single collection of codepoints known as a script . A character's script is helpful in determining which language the character might be in. For example, knowing that '–ë' is in Cyrillic script indicates that modern text containing that character is likely from a Slavic language such as Russian or Ukrainian.\n","\n","TensorFlow provides the `tf.strings.unicode_script` operation to determine which script a given codepoint uses. The script codes are int32 values corresponding to International Components for Unicode (ICU) UScriptCode values."]},{"cell_type":"code","metadata":{"id":"5tNtrkrFKWhr","colab_type":"code","outputId":"91b8c27f-8fbb-461c-c047-dda0f30ed95b","executionInfo":{"status":"ok","timestamp":1579205779092,"user_tz":360,"elapsed":16825,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#basically ask from which language it is from\n","uscript = tf.strings.unicode_script([33464, 1041])  # ['Ëä∏', '–ë']\n","\n","print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[17  8]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RzHV_Rr9Kspf","colab_type":"text"},"source":["The `tf.strings.unicode_script` operation can also be applied to multidimensional `tf.Tensors` or `tf.RaggedTensors` of codepoints:"]},{"cell_type":"code","metadata":{"id":"v0gZ06mtKmwF","colab_type":"code","outputId":"a4cfb1f7-f44d-4fb1-cc5a-a6ca793d3671","executionInfo":{"status":"ok","timestamp":1579205779094,"user_tz":360,"elapsed":16820,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["print(tf.strings.unicode_script(batch_chars_ragged)) #Regresa 0 al final"],"execution_count":25,"outputs":[{"output_type":"stream","text":["<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DCx-kcD5lHv1","colab_type":"text"},"source":["#Example: Simple segmentation\n","\n","Segmentation is the task of splitting text into word-like units. This is often easy when space characters are used to separate words, but some languages (like Chinese and Japanese) do not use spaces, and some languages (like German) contain long compounds that must be split in order to analyze their meaning. In web text, different languages and scripts are frequently mixed together, as in \"NYÊ†™‰æ°\" (New York Stock Exchange).\n","\n","We can perform very rough segmentation (without implementing any ML models) by using changes in script to approximate word boundaries. This will work for strings like the \"NYÊ†™‰æ°\" example above. It will also work for most languages that use spaces, as the space characters of various scripts are all classified as USCRIPT_COMMON, a special script code that differs from that of any actual text."]},{"cell_type":"code","metadata":{"id":"FCrlLCnUKxwA","colab_type":"code","colab":{}},"source":["# dtype: string; shape: [num_sentences]\n","#\n","# The sentences to process.  Edit this line to try out different inputs!\n","sentence_texts = [u'Hello, world.', u'‰∏ñÁïå„Åì„Çì„Å´„Å°„ÅØ']\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ut6_ghRlXoH","colab_type":"code","outputId":"dd3c067f-c341-421b-b242-cc3963a87b3f","executionInfo":{"status":"ok","timestamp":1579205779095,"user_tz":360,"elapsed":16812,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#First, we decode the sentences into character codepoints, and find the script identifeir for each character.\n","\n","# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n","#\n","# sentence_char_codepoint[i, j] is the codepoint for the j'th character in\n","# the i'th sentence.\n","sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n","print(sentence_char_codepoint) #literally the code for every character\n","\n","# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n","#\n","# sentence_char_scripts[i, j] is the unicode script of the j'th character in\n","# the i'th sentence.\n","sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)  #I think this is the language dictionary to which it belongs\n","print(sentence_char_script)\n","#This is to find where the boundary between languages is, eg. if some words are mixed with other languages.\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n","<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3HqE_SvemCu_","colab_type":"text"},"source":["Next, we use those script identifiers to determine where word boundaries should be added. We add a word boundary at the beginning of each sentence, and for each character whose script differs from the previous character:"]},{"cell_type":"code","metadata":{"id":"u4SWvIt7lhE9","colab_type":"code","outputId":"43a21fa5-65e5-499e-c184-5955d8e6999e","executionInfo":{"status":"ok","timestamp":1579205779095,"user_tz":360,"elapsed":16806,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n","#\n","# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n","# sentence is the start of a word.\n","sentence_char_starts_word = tf.concat( #Esto es un array de True o False si la siguiente es diferente a la actual\n","    [tf.fill([sentence_char_script.nrows(), 1], True),\n","     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n","    axis=1)\n","\n","# dtype: int64; shape: [num_words]\n","#\n","# word_starts[i] is the index of the character that starts the i'th word (in\n","# the flattened list of characters from all sentences).\n","word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1) #sin squeeze es shape 6,1 el squeeze lo hace shape 6,\n","print(word_starts)\n","#Esto es en que posici√≥n empieza un tipo diferente de texto"],"execution_count":28,"outputs":[{"output_type":"stream","text":["tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e-tXTXbAmPML","colab_type":"code","outputId":"56639c9f-cdb0-4ed0-d209-f619044e9071","executionInfo":{"status":"ok","timestamp":1579205779096,"user_tz":360,"elapsed":16800,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":146}},"source":["#Ejemplo de antes del squeeze\n","tf.where(sentence_char_starts_word.values)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(6, 1), dtype=int64, numpy=\n","array([[ 0],\n","       [ 5],\n","       [ 7],\n","       [12],\n","       [13],\n","       [15]])>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"4zDFcYJ8m8Nc","colab_type":"text"},"source":["We can then use those start offsets to build a `RaggedTensor` containing the list of words from all batches:"]},{"cell_type":"code","metadata":{"id":"VkAdFt9lm6lr","colab_type":"code","outputId":"751e3e7e-996a-4712-e622-cc333587c59e","executionInfo":{"status":"ok","timestamp":1579205779096,"user_tz":360,"elapsed":16793,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# dtype: int32; shape: [num_words, (num_chars_per_word)]\n","#\n","# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n","# i'th word.\n","word_char_codepoint = tf.RaggedTensor.from_row_starts(\n","    values=sentence_char_codepoint.values,\n","    row_starts=word_starts)\n","print(word_char_codepoint)\n","#Basicamente separar las palabras (characters) en sus respectivos lenguajes"],"execution_count":30,"outputs":[{"output_type":"stream","text":["<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zoozsirKnRDN","colab_type":"text"},"source":["And finally, we can segment the word codepoints RaggedTensor back into sentences:"]},{"cell_type":"code","metadata":{"id":"ksmZBcv5nDre","colab_type":"code","outputId":"d43bf4aa-68ca-453a-8450-969123c93d86","executionInfo":{"status":"ok","timestamp":1579205779233,"user_tz":360,"elapsed":16924,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# dtype: int64; shape: [num_sentences]\n","#\n","# sentence_num_words[i] is the number of words in the i'th sentence.\n","sentence_num_words = tf.reduce_sum(\n","    tf.cast(sentence_char_starts_word, tf.int64),\n","    axis=1)\n","\n","# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n","#\n","# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n","# in the j'th word in the i'th sentence.\n","sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n","    values=word_char_codepoint,\n","    row_lengths=sentence_num_words)\n","print(sentence_word_char_codepoint)\n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kp60fcW2nUrc","colab_type":"code","outputId":"6c0beb21-1f7c-4637-cf62-463ecf903ced","executionInfo":{"status":"ok","timestamp":1579205779235,"user_tz":360,"elapsed":16921,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#To make the final result easier to read, we can encode it back into UTF-8 strings:\n","sentence_num_words #[0] es 4, es decir que hay 5 characters en la primera palabra?, con [1] es 2, hay 3 en la segunda?, no cuadra\n"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=int64, numpy=array([4, 2])>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"6JffpzCrnwF6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"5d8613ca-58bd-45c8-cdc6-b9872ce54847","executionInfo":{"status":"ok","timestamp":1579205779236,"user_tz":360,"elapsed":16916,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()\n"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[b'Hello', b', ', b'world', b'.'],\n"," [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n","  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"cy1GItiH_3Re","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}