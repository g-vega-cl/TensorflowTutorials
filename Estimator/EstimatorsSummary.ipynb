{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EstimatorsSummary.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhlbEQDTYYpPT74pK9/Nxd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Tuey_9AOpDDT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oGBpbSOJ6Kzl","colab_type":"text"},"source":["#Data types:\n","<ul>\n","  <li>Estimator?</li>\n","  <li>BatchDataset</li>\n","  <li>feature_column.dense_features_v2.DenseFeatures</li>\n","  <li>CrossedColumn (This are two columns and ¿merges them? into one)</li>\n","  <li>IndicatorColumn: this one is one-hot-encoded</li>\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"QqTWo5IH6c6f","colab_type":"text"},"source":["#Estimators\n","#Overview of programming with Estimators\n","\n","Now that you have the data set up, you can define a model using a TensorFlow Estimator. An Estimator is any class derived from `tf.estimator.Estimator`. TensorFlow provides a collection of `tf.estimator `(for example, LinearRegressor) to implement common ML algorithms. custom estimators may be made.\n","\n","To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n","\n","    1. Create one or more input functions.\n","      #to supply data for training, evaluating, and prediction.\n","      #An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n","      *features - A Python dictionary in which: Each key is the name of a feature AND each value is an array containing all of that feature's values.\n","      *label - An array containing the values of the label for every example.\n","    2. Define the model's feature columns. #Feature columns describe how to use the input.\n","      A feature column is an object describing how the model should use raw input data from the features dictionary. \n","    3. Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n","    4. Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data.\n"]},{"cell_type":"markdown","metadata":{"id":"T_lzMtCiY-vR","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"xVDvMTViY5Zj","colab_type":"text"},"source":["#Feature Engineering for the Model\n","\n","Estimators use a system called feature columns to describe how the model should interpret each of the raw input features. An Estimator expects a vector of numeric inputs, and feature columns describe how the model should convert each feature.\n","\n","Selecting and crafting the right set of feature columns is key to learning an effective model. A feature column can be either one of the raw inputs in the original features dict (a base feature column), or any new columns created using transformations defined over one or multiple base columns (a derived feature columns).\n","\n","Feature columns work with all TensorFlow estimators and their purpose is to define the features used for modeling. Additionally, they provide some feature engineering capabilities like one-hot-encoding, normalization, and bucketization."]},{"cell_type":"markdown","metadata":{"id":"PUZev3reZULK","colab_type":"text"},"source":["**NOTE:** to define the feature columns the process seems simple:\n","You take the name of the categorical columns and of the numerical columns (both should be apart). (You could also one-hot-encode the columns as in: https://www.tensorflow.org/tutorials/estimator/boosted_trees)\n","an example of the titanic dataset:\n","\n","\n","```\n","#Base Feature Columns\n","CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n","                       'embark_town', 'alone'] #the categorial column names\n","NUMERIC_COLUMNS = ['age', 'fare'] #the numerical column names\n","\n","feature_columns = [] #creating the feature column array\n","for feature_name in CATEGORICAL_COLUMNS: #getting the categorical column names\n","  vocabulary = dftrain[feature_name].unique() #creating a vocabilary, which is basically all the possibilities of categories in the column\n","  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)) #\n","  #this creates a column of type VocabularyListCategoricalColumn, with the column name as 'key' and its possibilites as the vocabulary\n","\n","for feature_name in NUMERIC_COLUMNS:\n","  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32)) #a numeric column\n","\n","```\n","**USUALLY AFTER BUILDING THE FEATURES, THE DATA IS BATCHED AND SHUFFLED**\n"]},{"cell_type":"markdown","metadata":{"id":"yleHhgv6_FOE","colab_type":"text"},"source":["#Train and evaluate the model\n","\n","Below you will do the following steps:\n","\n","    1. Initialize the model, specifying the features and hyperparameters.\n","    2. Feed the training data to the model using the train_input_fn and train the model using the train function.\n","    3. You will assess model performance using the evaluation set—in this example, the dfeval DataFrame. You will verify that the predictions match the labels from the y_eval array.\n","\n","\n","Super simple linear example\n","```\n","#Adding the feature_columns\n","linear_est = tf.estimator.LinearClassifier(feature_columns,n_batches_per_layer=n_batches) #This is like the previous model, simple linear\n","\n","# Train model.\n","linear_est.train(train_input_fn, max_steps=100)\n","\n","# Evaluation.\n","result = linear_est.evaluate(eval_input_fn)\n","clear_output()\n","print(pd.Series(result))\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"tv-e6ZyK_DAV","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w3CDtGY09Q-j","colab_type":"text"},"source":["#Useful functions:\n","<ul>\n","  <li>\n","    <a>tf.data.Dataset.from_tensor_slices</a>: Esto toma los features y su label y lo transforma a BatchDataset. Nota, puedes ponerlo sin las labels.\n","    \n","    ejemplo: tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) #creo que depende del formato de tus datos el dict() es relevante\n","    #Note: usually after doing this you shuffle the dataset:\n","    ds = ds.shuffle(1000) #shuffling the dataset\n","    #And then create batches:\n","    ds = ds.batch(batch_size).repeat(num_epochs)\n","  </li>\n","  <li><a>tf.feature_column.indicator_colum(categorical_column_of_type_VocabularyListCategoricalColumn)</a>.\n","\n","    this transforms from vocabularylist.... column into a indicator_column.\n","    Which is needed to pass into a tf.keras.layers.DenseFeatures\n","  </li>\n","  <li><a>tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))</a>: this transforms a column into an indicator column and one-hot-encodes it, (the feature name is what you want to encode and the vocabulary is how many values there are to encode) (see in: https://www.tensorflow.org/tutorials/estimator/boosted_trees) \n","    \n","    example = dict(dftrain.head(1)) #get a dictionary of the first passenger\n","    class_fc = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('class', ('First', 'Second', 'Third')))\n","    \n","    print('Feature value: \"{}\"'.format(example['class'].iloc[0])) #Show the value (non-encoded) of the feature we want\n","    print('One-hot encoded: ', tf.keras.layers.DenseFeatures([class_fc])(example).numpy()) #showing the one-hot\n","\n","  </li>\n","\n","  <li><a>dataset = dataset.shuffle()</a></li>\n","  <li><a>tf.keras.estimator.model_to_estimator(keras_model=model,model_dir=model_dir)</a> Builds an estimator from a keras_model </li>\n","  <li><a>clear_output()</a> importar de: from IPython.display import clear_output . Lo que hace es que remueve los warnings y eso del output después de una función</li>\n","\n","</ul>"]},{"cell_type":"markdown","metadata":{"id":"RFC5i4p4Jxzk","colab_type":"text"},"source":["#NOTES\n","  *Study(understand) ROC Curve (from Linear model tutorial):\n","  https://www.youtube.com/watch?v=4jRBRDbJemM\n","  \n","  *It seems like the estimators are only-tensorflow models, (no-keras included), when you use the layers and use the model.add(xxxx) thats keras"]},{"cell_type":"code","metadata":{"id":"vTSalET-6fBh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}