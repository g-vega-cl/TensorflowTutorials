{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2019_01_07-MovieReviewClassification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tmYxk95NUB_g","colab_type":"code","colab":{}},"source":["#https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n","#Text classification with TensorFlow Hub: Movie review"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8z-w9PO7UJMf","colab_type":"code","outputId":"350a81a0-a480-4f94-c4e5-9e0d3a776d66","executionInfo":{"status":"ok","timestamp":1578426786955,"user_tz":360,"elapsed":9349,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","# TensorFlow and tf.keras\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bXt78owjUnJx","colab_type":"code","outputId":"6c912799-6587-4e10-e770-09b1e2bb0138","executionInfo":{"status":"ok","timestamp":1578426795433,"user_tz":360,"elapsed":17726,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["!pip install -q tensorflow-hub\n","!pip install -q tensorflow-datasets\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","\n","print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"Hub version: \", hub.__version__)\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Version:  2.1.0-rc1\n","Eager mode:  True\n","Hub version:  0.7.0\n","GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sfd5R5PAUp0i","colab_type":"code","outputId":"e310cef5-d462-439c-8677-99e5f9a8b301","executionInfo":{"status":"ok","timestamp":1578427136365,"user_tz":360,"elapsed":1683,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["#Download the dataset\n","train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n","(train_data, validation_data), test_data = tfds.load(\n","    name=\"imdb_reviews\", \n","    split=(train_validation_split, tfds.Split.TEST),\n","    as_supervised=True)\n","\"\"\"\n","#I basically tried to see hpw the data was written, but it is a mess\n","#Its better if I follow the data adquisition and then explore its shapes.\n","\n","movie_reviews = tfds.load(name=\"imdb_reviews\")\n","#movie_reviews['train']\n","#movie_reviews['test']\n","\n","print(next(iter(movie_reviews['train'].batch(10))))\n","\n","#No idea how the dataset is written but this gives you the data\n","train_examples_batch, train_labels_batch = next(iter(movie_reviews['train'].batch(10)))\n","\n","#train_labels_batch\n","\"\"\""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n#I basically tried to see hpw the data was written, but it is a mess\\n#Its better if I follow the data adquisition and then explore its shapes.\\n\\nmovie_reviews = tfds.load(name=\"imdb_reviews\")\\n#movie_reviews[\\'train\\']\\n#movie_reviews[\\'test\\']\\n\\nprint(next(iter(movie_reviews[\\'train\\'].batch(10))))\\n\\n#No idea how the dataset is written but this gives you the data\\ntrain_examples_batch, train_labels_batch = next(iter(movie_reviews[\\'train\\'].batch(10)))\\n\\n#train_labels_batch\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"v6X2EdBkVBZA","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Build the model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltE84kHIWRcK","colab_type":"code","colab":{}},"source":["#Note:One way to represent the text is to convert sentences into embeddings vectors. \n","#We can use a pre-trained text embedding as the first layer, \n","#which will have three advantages:\n","\"\"\"\n","we don't have to worry about text preprocessing,\n","we can benefit from transfer learning,\n","the embedding has a fixed size, so it's simpler to process.\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f6gKArlCXhgI","colab_type":"code","outputId":"f4c37475-13aa-42f6-ccc2-1f222d1a62ec","executionInfo":{"status":"error","timestamp":1578682500933,"user_tz":360,"elapsed":1048,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":247}},"source":["#In this tutorial we take a pre-made text embedding model\n","embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n","hub_layer = hub.KerasLayer(embedding, input_shape=[], \n","                           dtype=tf.string, trainable=True)\n","train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n","train_examples_batch\n","hub_layer(train_examples_batch[:1]) #Hace un valor de shape (1,20),\n","#el 1 es por el [:1], el 20 es porque es as√≠, probablemente por el embedidng\n","#Creo que con esto puedes pasar cualquier texto a un array...\n","#Interesante...\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d06e6932b30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m hub_layer = hub.KerasLayer(embedding, input_shape=[], \n\u001b[0m\u001b[1;32m      3\u001b[0m                            dtype=tf.string, trainable=True)\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_examples_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'hub' is not defined"]}]},{"cell_type":"code","metadata":{"id":"h6utU5mFlYl9","colab_type":"code","outputId":"d71815df-bf11-41f5-d7d0-8e2568f11d29","executionInfo":{"status":"ok","timestamp":1578427422885,"user_tz":360,"elapsed":1918,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":276}},"source":["model = tf.keras.Sequential()\n","model.add(hub_layer) #The first layer is a TensorFlow Hub layer. This layer uses a pre-trained Saved Model to map a sentence into its embedding vector.\n","#The resulting dimensions are: (num_examples, embedding_dimension)\n","#En este caso la embedding dim es 20, (default del embedder?)\n","model.add(tf.keras.layers.Dense(16, activation='relu'))\n","model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","\n","model.summary()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","keras_layer_6 (KerasLayer)   (None, 20)                400020    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 16)                336       \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 17        \n","=================================================================\n","Total params: 400,373\n","Trainable params: 400,373\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-68zsqWqWvcE","colab_type":"code","outputId":"265915af-27ee-4f79-c3cc-e744367bd9f8","executionInfo":{"status":"ok","timestamp":1578427519985,"user_tz":360,"elapsed":977,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(model.output_shape)\n","#Note: our final output shape is 1 because we want just 1 value, 0 or 1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TcE9qNGznHra","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Loss function and optimizer\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"12wctDTpnLRB","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","#The parameters we chose are default for a probability single classification"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yxYgLwGYnl0M","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Train the model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vd3tXlqjnuTb","colab_type":"code","outputId":"3999a639-a566-446e-daf3-5d24b25adcc3","executionInfo":{"status":"ok","timestamp":1578427969717,"user_tz":360,"elapsed":129734,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":776}},"source":["#Train the model for 20 epochs in mini-batches of 512 samples.\n","history = model.fit(train_data.shuffle(10000).batch(512),\n","                    epochs=20,\n","                    validation_data=validation_data.batch(512),\n","                    verbose=1)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","30/30 [==============================] - 7s 228ms/step - loss: 1.0445 - accuracy: 0.4669 - val_loss: 0.8593 - val_accuracy: 0.4553\n","Epoch 2/20\n","30/30 [==============================] - 6s 191ms/step - loss: 0.8033 - accuracy: 0.4857 - val_loss: 0.7554 - val_accuracy: 0.5300\n","Epoch 3/20\n","30/30 [==============================] - 6s 205ms/step - loss: 0.7210 - accuracy: 0.5592 - val_loss: 0.6916 - val_accuracy: 0.5884\n","Epoch 4/20\n","30/30 [==============================] - 6s 215ms/step - loss: 0.6593 - accuracy: 0.6211 - val_loss: 0.6385 - val_accuracy: 0.6424\n","Epoch 5/20\n","30/30 [==============================] - 6s 200ms/step - loss: 0.6065 - accuracy: 0.6733 - val_loss: 0.5931 - val_accuracy: 0.6896\n","Epoch 6/20\n","30/30 [==============================] - 7s 220ms/step - loss: 0.5614 - accuracy: 0.7180 - val_loss: 0.5528 - val_accuracy: 0.7245\n","Epoch 7/20\n","30/30 [==============================] - 6s 211ms/step - loss: 0.5178 - accuracy: 0.7595 - val_loss: 0.5105 - val_accuracy: 0.7608\n","Epoch 8/20\n","30/30 [==============================] - 6s 216ms/step - loss: 0.4711 - accuracy: 0.7941 - val_loss: 0.4710 - val_accuracy: 0.7879\n","Epoch 9/20\n","30/30 [==============================] - 6s 215ms/step - loss: 0.4290 - accuracy: 0.8234 - val_loss: 0.4377 - val_accuracy: 0.8094\n","Epoch 10/20\n","30/30 [==============================] - 6s 207ms/step - loss: 0.3933 - accuracy: 0.8409 - val_loss: 0.4111 - val_accuracy: 0.8245\n","Epoch 11/20\n","30/30 [==============================] - 7s 218ms/step - loss: 0.3650 - accuracy: 0.8558 - val_loss: 0.3883 - val_accuracy: 0.8350\n","Epoch 12/20\n","30/30 [==============================] - 6s 216ms/step - loss: 0.3386 - accuracy: 0.8681 - val_loss: 0.3686 - val_accuracy: 0.8461\n","Epoch 13/20\n","30/30 [==============================] - 7s 218ms/step - loss: 0.3130 - accuracy: 0.8785 - val_loss: 0.3527 - val_accuracy: 0.8538\n","Epoch 14/20\n","30/30 [==============================] - 7s 220ms/step - loss: 0.2913 - accuracy: 0.8872 - val_loss: 0.3393 - val_accuracy: 0.8576\n","Epoch 15/20\n","30/30 [==============================] - 6s 203ms/step - loss: 0.2729 - accuracy: 0.8957 - val_loss: 0.3302 - val_accuracy: 0.8634\n","Epoch 16/20\n","30/30 [==============================] - 6s 216ms/step - loss: 0.2566 - accuracy: 0.9053 - val_loss: 0.3201 - val_accuracy: 0.8658\n","Epoch 17/20\n","30/30 [==============================] - 6s 202ms/step - loss: 0.2403 - accuracy: 0.9104 - val_loss: 0.3124 - val_accuracy: 0.8695\n","Epoch 18/20\n","30/30 [==============================] - 6s 210ms/step - loss: 0.2277 - accuracy: 0.9169 - val_loss: 0.3076 - val_accuracy: 0.8720\n","Epoch 19/20\n","30/30 [==============================] - 6s 213ms/step - loss: 0.2134 - accuracy: 0.9240 - val_loss: 0.3022 - val_accuracy: 0.8743\n","Epoch 20/20\n","30/30 [==============================] - 7s 221ms/step - loss: 0.2010 - accuracy: 0.9283 - val_loss: 0.2986 - val_accuracy: 0.8752\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9y8SPsjGoXV6","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Evaluate the model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2GrJgypoaMw","colab_type":"code","outputId":"343aedfc-7ac4-493c-94b1-e3557b46457e","executionInfo":{"status":"ok","timestamp":1578428080274,"user_tz":360,"elapsed":4381,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["results = model.evaluate(test_data.batch(512), verbose=2)\n","\n","for name, value in zip(model.metrics_names, results):\n","  print(\"%s: %.3f\" % (name, value))\n","\n","#The previous one is literally just printing this pretty\n","print(results)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loss: 0.318\n","accuracy: 0.862\n","[0.3179040052452866, 0.86168]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-7w4X-IzpF-c","colab_type":"code","outputId":"b7eb8553-1947-451f-bfeb-09a61b3a6e98","executionInfo":{"status":"ok","timestamp":1578428047134,"user_tz":360,"elapsed":571,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.3179040052452866, 0.86168]"]},"metadata":{"tags":[]},"execution_count":28}]}]}