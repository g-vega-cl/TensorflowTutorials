{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2020_01_24-DistributeKeras","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO1GAI3sA5GOtBH7LQDG/Ix"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kfJ7eHoidgVg","colab_type":"code","colab":{}},"source":["#https://www.tensorflow.org/tutorials/distribute/keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PR73vwOPdqrk","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","# TensorFlow and tf.keras\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6DnPCKA6d4Si","colab_type":"text"},"source":["#Overview\n","\n","The `tf.distribute.Strategy` API provides an abstraction for distributing your training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.\n","\n","This tutorial uses the `tf.distribute.MirroredStrategy`, which does in-graph replication with synchronous training on many GPUs on one machine. Essentially, it copies all of the model's variables to each processor. Then, it uses `all-reduce` to combine the gradients from all processors and applies the combined value to all copies of the model.\n","\n","MirroredStrategy is one of several distribution strategy available in TensorFlow core."]},{"cell_type":"markdown","metadata":{"id":"wUH8hMuNeJNa","colab_type":"text"},"source":["#Keras API\n","\n","This example uses the `tf.keras` API to build the model and training loop."]},{"cell_type":"code","metadata":{"id":"kmppGL8-d1zG","colab_type":"code","colab":{}},"source":["import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bya-d0oweaTT","colab_type":"text"},"source":["#Download the dataset\n","\n","Download the MNIST dataset and load it from TensorFlow Datasets. This returns a dataset in `tf.data` format.\n","\n","Setting with_info to True includes the metadata for the entire dataset, which is being saved here to info. Among other things, this metadata object includes the number of train and test examples. "]},{"cell_type":"code","metadata":{"id":"nfbkxIqteYXC","colab_type":"code","colab":{}},"source":["datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n","\n","mnist_train, mnist_test = datasets['train'], datasets['test']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSVDJJUZeky8","colab_type":"text"},"source":["#Define distribution strategy\n","\n","Create a `MirroredStrategy` object. This will handle distribution, and provides a context manager (`tf.distribute.MirroredStrategy.scope`) to build your model inside."]},{"cell_type":"code","metadata":{"id":"YphX9Twjeizl","colab_type":"code","outputId":"38d05a00-36d1-4e41-ed9d-610a5a18d5d9","executionInfo":{"status":"ok","timestamp":1579912149859,"user_tz":360,"elapsed":601,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["strategy = tf.distribute.MirroredStrategy()\n","strategy"],"execution_count":25,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy at 0x7f9bfe8eb0f0>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"6Tjfbs8Ie85q","colab_type":"code","outputId":"0805d09f-bb01-48de-b247-89690e35e318","executionInfo":{"status":"ok","timestamp":1579912149860,"user_tz":360,"elapsed":596,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Number of devices: 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ij2iatcsfP2I","colab_type":"text"},"source":["#Setup input pipeline\n","\n","When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly."]},{"cell_type":"code","metadata":{"id":"VMvizV48e9HO","colab_type":"code","colab":{}},"source":["# You can also do info.splits.total_num_examples to get the total\n","# number of examples in the dataset.\n","\n","num_train_examples = info.splits['train'].num_examples\n","num_test_examples = info.splits['test'].num_examples\n","\n","BUFFER_SIZE = 10000\n","\n","BATCH_SIZE_PER_REPLICA = 64\n","BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBKbqQWLf445","colab_type":"code","colab":{}},"source":["#Pixel values, which are 0-255, have to be normalized to the 0-1 range. Define this scale in a function.\n","def scale(image, label):\n","  image = tf.cast(image, tf.float32)\n","  image /= 255\n","\n","  return image, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJh4TUxWf6rZ","colab_type":"code","colab":{}},"source":["#Apply this function to the training and test data, shuffle the training data, and batch it for training. \n","#Notice we are also keeping an in-memory cache of the training data to improve performance.\n","train_dataset = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).cache()\n","eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikeP7YYqgC77","colab_type":"code","outputId":"2e8ad69d-f28d-4002-e7ad-9394ecbdaabf","executionInfo":{"status":"ok","timestamp":1579912150057,"user_tz":360,"elapsed":780,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["mnist_train"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_OptionsDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"njNkhHhmGmbc","colab_type":"text"},"source":["#Create the model\n","\n","Create and compile the Keras model in the context of strategy.scope."]},{"cell_type":"code","metadata":{"id":"Zj4N47m7g0S9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"outputId":"ef1e958b-b784-42ff-c849-c6ec9d96d4b4","executionInfo":{"status":"ok","timestamp":1579912202308,"user_tz":360,"elapsed":7075,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["#I think you have to add the strategy.scope to properly distribute the model\n","#I think what it really does is that it allows the model to be properly saved.\n","with strategy.scope():\n","  model = tf.keras.Sequential([\n","      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(64, activation='relu'),\n","      tf.keras.layers.Dense(10, activation='softmax')\n","  ])\n","\n","  model.compile(loss='sparse_categorical_crossentropy',\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=['accuracy'])\n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"xc6NVKOGGx0O","colab_type":"text"},"source":["#Define the callbacks\n","\n","The callbacks used here are:\n","\n","    TensorBoard: This callback writes a log for TensorBoard which allows you to visualize the graphs.\n","    Model Checkpoint: This callback saves the model after every epoch.\n","    Learning Rate Scheduler: Using this callback, you can schedule the learning rate to change after every epoch/batch.\n","\n","For illustrative purposes, add a print callback to display the learning rate in the notebook."]},{"cell_type":"code","metadata":{"id":"5lW0VZ36GuxP","colab_type":"code","colab":{}},"source":["# Define the checkpoint directory to store the checkpoints\n","\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsX6A1jfHQda","colab_type":"code","colab":{}},"source":["# Function for decaying the learning rate.\n","# You can define any decay function you need.\n","def decay(epoch):\n","  if epoch < 3:\n","    return 1e-3\n","  elif epoch >= 3 and epoch < 7:\n","    return 1e-4\n","  else:\n","    return 1e-5\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9WjQxuB9HQrg","colab_type":"code","colab":{}},"source":["# Callback for printing the LR at the end of each epoch.\n","class PrintLR(tf.keras.callbacks.Callback): \n","  def on_epoch_end(self, epoch, logs=None):\n","    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n","                                                      model.optimizer.lr.numpy()))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"erHW1O0jHYu6","colab_type":"code","colab":{}},"source":["callbacks = [\n","    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n","    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n","                                       save_weights_only=True),\n","    tf.keras.callbacks.LearningRateScheduler(decay),\n","    PrintLR()\n","]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ngLyAALDH1fo","colab_type":"text"},"source":["#Train and evaluate\n","\n","Now, train the model in the usual way, calling fit on the model and passing in the dataset created at the beginning of the tutorial. This step is the same whether you are distributing the training or not."]},{"cell_type":"code","metadata":{"id":"GCXxdJC0H14N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"cd9b2f7b-c9c4-445a-f1d0-2c047db296c5","executionInfo":{"status":"ok","timestamp":1579912574633,"user_tz":360,"elapsed":79190,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["model.fit(train_dataset, epochs=12, callbacks=callbacks)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch 1/12\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"},{"output_type":"stream","text":["    938/Unknown - 25s 27ms/step - loss: 0.1947 - accuracy: 0.9420\n","Learning rate for epoch 1 is 0.0010000000474974513\n","938/938 [==============================] - 25s 27ms/step - loss: 0.1947 - accuracy: 0.9420\n","Epoch 2/12\n","931/938 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9812\n","Learning rate for epoch 2 is 0.0010000000474974513\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0630 - accuracy: 0.9812\n","Epoch 3/12\n","931/938 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9873\n","Learning rate for epoch 3 is 0.0010000000474974513\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0429 - accuracy: 0.9873\n","Epoch 4/12\n","932/938 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9929\n","Learning rate for epoch 4 is 9.999999747378752e-05\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0242 - accuracy: 0.9929\n","Epoch 5/12\n","932/938 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9947\n","Learning rate for epoch 5 is 9.999999747378752e-05\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0210 - accuracy: 0.9947\n","Epoch 6/12\n","937/938 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9954\n","Learning rate for epoch 6 is 9.999999747378752e-05\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0192 - accuracy: 0.9955\n","Epoch 7/12\n","934/938 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9959\n","Learning rate for epoch 7 is 9.999999747378752e-05\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0176 - accuracy: 0.9959\n","Epoch 8/12\n","937/938 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9966\n","Learning rate for epoch 8 is 9.999999747378752e-06\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0152 - accuracy: 0.9966\n","Epoch 9/12\n","933/938 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9968\n","Learning rate for epoch 9 is 9.999999747378752e-06\n","938/938 [==============================] - 5s 6ms/step - loss: 0.0149 - accuracy: 0.9968\n","Epoch 10/12\n","928/938 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9969\n","Learning rate for epoch 10 is 9.999999747378752e-06\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0148 - accuracy: 0.9969\n","Epoch 11/12\n","936/938 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9969\n","Learning rate for epoch 11 is 9.999999747378752e-06\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0146 - accuracy: 0.9969\n","Epoch 12/12\n","933/938 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9970\n","Learning rate for epoch 12 is 9.999999747378752e-06\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0144 - accuracy: 0.9970\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9be70eca90>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"pU0hqkrKH3Gi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":368},"outputId":"0ed3064e-96c2-48c1-ed6d-2ca22a6e368d","executionInfo":{"status":"ok","timestamp":1579912575637,"user_tz":360,"elapsed":63000,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["# check the checkpoint directory\n","!ls {checkpoint_dir}\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["checkpoint\t\t     ckpt_4.data-00000-of-00002\n","ckpt_10.data-00000-of-00002  ckpt_4.data-00001-of-00002\n","ckpt_10.data-00001-of-00002  ckpt_4.index\n","ckpt_10.index\t\t     ckpt_5.data-00000-of-00002\n","ckpt_11.data-00000-of-00002  ckpt_5.data-00001-of-00002\n","ckpt_11.data-00001-of-00002  ckpt_5.index\n","ckpt_11.index\t\t     ckpt_6.data-00000-of-00002\n","ckpt_12.data-00000-of-00002  ckpt_6.data-00001-of-00002\n","ckpt_12.data-00001-of-00002  ckpt_6.index\n","ckpt_12.index\t\t     ckpt_7.data-00000-of-00002\n","ckpt_1.data-00000-of-00002   ckpt_7.data-00001-of-00002\n","ckpt_1.data-00001-of-00002   ckpt_7.index\n","ckpt_1.index\t\t     ckpt_8.data-00000-of-00002\n","ckpt_2.data-00000-of-00002   ckpt_8.data-00001-of-00002\n","ckpt_2.data-00001-of-00002   ckpt_8.index\n","ckpt_2.index\t\t     ckpt_9.data-00000-of-00002\n","ckpt_3.data-00000-of-00002   ckpt_9.data-00001-of-00002\n","ckpt_3.data-00001-of-00002   ckpt_9.index\n","ckpt_3.index\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uT-a9wpQH8qi","colab_type":"text"},"source":["To see how the model perform, load the latest checkpoint and call evaluate on the test data.\n","\n","Call evaluate as before using appropriate datasets."]},{"cell_type":"code","metadata":{"id":"RoY-IeTxH8P3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":129},"outputId":"14b39056-2221-4c41-9c86-0c683b3c2738","executionInfo":{"status":"ok","timestamp":1579912578854,"user_tz":360,"elapsed":52828,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","eval_loss, eval_acc = model.evaluate(eval_dataset)\n","\n","print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n"],"execution_count":40,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"],"name":"stderr"},{"output_type":"stream","text":["    157/Unknown - 3s 19ms/step - loss: 0.0395 - accuracy: 0.9869Eval loss: 0.0395005501808219, Eval Accuracy: 0.9868999719619751\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FrtlVuZAH_hC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"9ad7650d-2e6d-4848-f0f7-b789ad9b97b5","executionInfo":{"status":"ok","timestamp":1579912598215,"user_tz":360,"elapsed":907,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["#To see the output, you can download and view the TensorBoard logs at the terminal.\n","#tensorboard --logdir=path/to/log-directory  <- This is supposed to work but it gives an error.\n","!ls -sh ./logs\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["total 4.0K\n","4.0K train\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kwypNuVnIFmZ","colab_type":"text"},"source":["#Export to SavedModel\n","\n","Export the graph and the variables to the platform-agnostic SavedModel format. After your model is saved, you can load it with or without the scope."]},{"cell_type":"code","metadata":{"id":"E-QRQFtoICzi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"0abed554-d0c5-40c6-8d3a-4fd9f606a321","executionInfo":{"status":"ok","timestamp":1579912619698,"user_tz":360,"elapsed":672,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["path = 'saved_model/'\n","model.save(path, save_format='tf')\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: saved_model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: saved_model/assets\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"RVsA6AAiIMzg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"d7964ed0-f974-421f-9b4b-64b0823a5752","executionInfo":{"status":"ok","timestamp":1579912766973,"user_tz":360,"elapsed":2866,"user":{"displayName":"Cesar vega","photoUrl":"","userId":"04805785551054582010"}}},"source":["#Load the model without strategy.scope.\n","unreplicated_model = tf.keras.models.load_model(path)\n","\n","unreplicated_model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(),\n","    metrics=['accuracy'])\n","\n","eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n","\n","print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n"],"execution_count":46,"outputs":[{"output_type":"stream","text":["    157/Unknown - 2s 15ms/step - loss: 0.0395 - accuracy: 0.9869Eval loss: 0.039500983970634236, Eval Accuracy: 0.9868999719619751\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SsXhL4N5I5pV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}